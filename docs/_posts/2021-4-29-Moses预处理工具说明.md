# Moses预处理工具说明

1. Normalize punctuation

   其中-l en是选择语言，同样例如德语: de等等。同样的操作应用于验证集和测试集。

   ```shell
   perl dir_name/mosesdecoder/scripts/tokenizer/normalize-punctuation.perl -l en  < data/train.en > data/train.norm.en
   ```

   

2. Tokenizer

   分词，对验证集和测试集做同样的操作

   ```shell
   perl dir_name/mosesdecoder/scripts/tokenizer/tokenizer.perl -a -l en 
   ```

   

3. Clean corpus

   控制句子有效长度，将数据集中过长/过短的句子删掉，例如设置有效长度在1~80个单词之间。

   ```shell
   perl path/to/mosesdecoder/scripts/training/clean-corpus-n.perl data/train.norm.tok en de data/train.norm.tok.clean 1 80
   ```

   这样会同时将双语语料进行操作，生成两个处理后的文件train.norm.tok.clean.en和train.norm.tok.clean.de。

   

4. Truecase

   Truecase不同于lowercase，lowercase相当于把数据中所有的字母小写，而truecase则会学习训练数据，判断句子中的名字、地点等需要大写的内容并将其保留，其余则小写，提升翻译时候的准确性。

   -  需要训练一个truecase模型。注意：只能使用训练集训练truecase模型。

   ```shell
   perl path/to/mosesdecoder/scripts/recaser/train-truecaser.perl -corpus data/train.norm.tok.clean.en -model path/to/truecase-model.en
   ```

   -  应用apply：将训练得到的英语truecase模型应用到训练集、校验集和测试集的英文上。

   ```shell
   perl dir_name/mosesdecoder/scripts/recaser/truecase.perl -model path/to/truecase-model.en < data/train.norm.tok.clean.en > data/train.norm.tok.clean.tc.en
   ```

   同样另一语言也要训练一个Truecase模型。



5. BPE

   这是subword mt的一种思想，将单词进行BPE编码，来自论文 [Neural Machine Translation of Rare Words with Subword Units](https://arxiv.org/pdf/1508.07909.pdf)

   [开源代码](https://github.com/rsennrich/subword-nmt)

   BPE将原有的单词拆解成了更小单元的高频词进行翻译，有效的解决了未登录词的问题。

   BPE 方法拆解成子字单元的具体效果可以通过下面的例子来进行说明：

   ```
   he is a good boy .
   h@@ e is a g@@ o@@ o@@ d b@@ oy .
   ```

   

   我们使用里面的python脚本对数据进行处理。

   - 训练BPE模型

     学习BPE模型分两种情况：一种是joint-BPE，即双语共同训练BPE模型，一般适用于两个语言差别不大的情况(如英语和法语)；另一种是各自训练一个bpe模型，适用于两个语言差距比较大的情况（如英语和汉语）。

     ```shell
     python path/to/subword_nmt/learn_bpe.py -s 10000 < data/train.norm.tok.clean.tc.en > data/codes.en
     ```

     -s后接的是bpe operations操作的次数，这里设置为10000。同样只对训练集训练。

   -  apply: 在训练集、验证集和测试集上进行应用。

     ```shell
     python path/to/subword_nmt/apply_bpe.py -c data/codes.en < data/train.norm.tok.clean.tc.en > data/train.pre.en
     ```

     翻译的时候使用的数据均是经过BPE编码的，因此翻译得到的result也是BPE后的，因此需要对result进行还原，还原回BPE之前的（即norm、tok、clean、tc处理后的）状态,再用它和BPE之前的 test.norm.tok.clean.tc.xxx 计算bleu值。

   - 还原

     ```shell
     cat result.bpe.de | sed -E 's/(@@ )|(@@ ?$)//g' > result.de
     ```

   - BLEU值计算

     ```shell
     perl multi-bleu.perl test.norm.tok.clean.tc.de < result.de
     ```

     

