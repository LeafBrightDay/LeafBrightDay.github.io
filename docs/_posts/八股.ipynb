{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if __name__ == 'main'作用：\n",
    "\n",
    "    确定脚本作用域。Python 中的if __name__ == 'main' 的作用和原理 __name__ 是当前模块名，当模块被直接运行时模块名为__main__ 。 这句话的意思就是，当模块被直接运行时，以下代码块将被运行，当模块是被导入时，代码块不被运行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三元运算符：\n",
    "\n",
    "    为真时的结果 if 判定条件 else 为假时的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: 1 if x > 5 else 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 易错点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yyxyyyzxyzxzx\n",
      "xyyyzxyzxzx\n"
     ]
    }
   ],
   "source": [
    "# strip只去掉首尾字符\n",
    "aa='  Yyxyyyzxyzxzxyy '\n",
    "print(aa.strip().strip('yy'))\n",
    "bb='  yyxyyyzxyzxzxyy '\n",
    "print(bb.strip().strip('yy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 6, 6, 6]\n"
     ]
    }
   ],
   "source": [
    "# lambda变量不会立即赋值\n",
    "def multipliers():\n",
    "    return [lambda x: i * x for i in range(4)]\n",
    "print([m(2) for m in multipliers()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for i in range(4):\n",
    "    tmp.append(lambda x: i * x)  # i并未赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "i = 0 \n",
    "for _ in range(4):\n",
    "    tmp.append(lambda x: i * x)  # i并未赋值\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0](2) # i取最后时刻的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "def multipliers():\n",
    "    # 添加了一个默认参数i=i\n",
    "    return [lambda x, i=i: i * x for i in range(4)]\n",
    "\n",
    "print([m(2) for m in multipliers()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 字符串格式化方法及其比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://zhuanlan.zhihu.com/p/71200288"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 正则表达式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re.group(0)与re.group()相同返回全部字符串，1以后才是re.groups()中的各个组\n",
    "\n",
    "re.groups()返回全部组的tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc-1\n",
      "('abc', '1')\n",
      "abc-1\n",
      "abc\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "m = re.match('(\\w\\w\\w)-(\\d?)', 'abc-123')\n",
    "print(m.group())  # abc-1\n",
    "print(m.groups())  # ('abc', '1')\n",
    "print(m.group(0))  # abc-1\n",
    "print(m.group(1))  # abc\n",
    "print(m.group(2))  # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are humans\n",
      "('we', 'are', 'humans')\n"
     ]
    }
   ],
   "source": [
    "sentence = 'we are humans'\n",
    "# .* 表示任意匹配除换行符（\\n、\\r）之外的任何单个或多个字符\n",
    "matched = re.match(r'(.*) (.*) (.*)', sentence)\n",
    "print(matched.group())  # we are humans\n",
    "print(matched.groups())  # ('we', 'are', 'humans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re.match 只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回 None，而 re.search 匹配整个字符串，直到找到一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(re.match('www', 'www.runoob.com').span()) # 在起始位置匹配 \n",
    "print(re.match('com', 'www.runoob.com')) # 不在起始位置匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(11, 14), match='com'>\n"
     ]
    }
   ],
   "source": [
    "print(re.search('com', 'www.runoob.com'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tr0y.wang/2019/04/08/Python%E5%9B%9B%E8%88%8D%E4%BA%94%E5%85%A5/\n",
    "\n",
    "奇进偶舍：\n",
    "\n",
    "    例如数 a.bcd，我们需要保留 2 位小数的话，要看小数点后第三位：\n",
    "    如果 d<5，直接舍去\n",
    "    如果 d>5，直接进位\n",
    "    如果 d == 5：\n",
    "    d 后面还有非 0 数字，例如 a.bcdef，f 非 0，那么要进位\n",
    "    d 后面没有数据，且 c 为偶数，那么不进位\n",
    "    d 后面没有数据，且 c 为奇数，那么要进位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11\n",
      "0.38\n"
     ]
    }
   ],
   "source": [
    "print(round(1.115, 2)) #1.11 #十进制小数转二进制时精度丢失的问题\n",
    "print(round(0.375, 2))  #0.38 #奇进偶舍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1149999999999999911182158029987476766109466552734375\n",
      "0.38\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal # decimal 是 Python 专门处理高精度的库\n",
    "print(Decimal(1.115))  #1.1149999999999999911182158029987476766109466552734375\n",
    "print(round(0.375, 2))  #0.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12\n",
      "0.14\n",
      "0.38\n"
     ]
    }
   ],
   "source": [
    "# 精确存储，奇进偶舍\n",
    "print(round(0.125, 2))\n",
    "print(round(0.135, 2))\n",
    "print(round(0.375, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n"
     ]
    }
   ],
   "source": [
    "print(Decimal(0.125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12\n",
      "2.67\n"
     ]
    }
   ],
   "source": [
    "# 非精确表示，精度截断，实际存储值要小\n",
    "print(round(0.115, 2))\n",
    "print(round(2.675, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.67499999999999982236431605997495353221893310546875\n"
     ]
    }
   ],
   "source": [
    "print(Decimal(2.675))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decimal\n",
    "# 需要精确数值计算的场景，应使用decimal模块，且不要用浮点数构造Decimal\n",
    "decimal.getcontext().rounding=decimal.ROUND_HALF_UP  #4舍5入  ROUND_HALF_DOWN 不入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14\n"
     ]
    }
   ],
   "source": [
    "c1=decimal.Decimal('2.135').quantize(decimal.Decimal('0.00'))\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14\n"
     ]
    }
   ],
   "source": [
    "c2=decimal.Decimal('2.145').quantize(decimal.Decimal('0.00'))\n",
    "print(c2) # 运行结果#2.15 ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 变量及作用域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 装饰器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "装饰器本质上是一个Python函数，它可以让其他函数在不需要做任何代码变动的前提下增加额外功能，装饰器的返回值也是一个函数对象。它经常用于有切面需求的场景，比如：插入日志、性能测试、事务处理、缓存、权限校验等场景。装饰器是解决这类问题的绝佳设计，有了装饰器，我们就可以抽离出大量与函数功能本身无关的雷同代码并继续重用。概括的讲，装饰器的作用就是为已经存在的对象添加额外的功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval()\n",
    "    \n",
    "    不启用 BatchNormalization 和 Dropout，保证BN和dropout不发生变化，pytorch框架会自动把BN和Dropout固定住，不会取平均，而是用训练好的值，不然的话，一旦test的batch_size过小，很容易就会被BN层影响结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch实现网络必须的两项\n",
    "\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "           self.xx\n",
    "           \n",
    "        def forward(self, x):\n",
    "           x = self.xx\n",
    "           output = self.xx\n",
    "           return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度学习为何耗CPU/GPU？\n",
    "\n",
    "1. backword阶段， 需要存储中间所有梯度结果。 O(n)内存复杂度；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 内存管理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C++ 内存分区：栈、堆、全局/静态存储区、常量存储区、代码区。\n",
    "\n",
    "    栈：存放函数的局部变量、函数参数、返回地址等，由编译器自动分配和释放。\n",
    "    堆：动态申请的内存空间，就是由 malloc 分配的内存块，由程序员控制它的分配和释放，如果程序执行结束还没有释放，操作系统会自动回收。\n",
    "    全局区/静态存储区（.bss 段和 .data 段）：存放全局变量和静态变量，程序运行结束操作系统自动释放，在 C 语言中，未初始化的放在 .bss 段中，初始化的放在 .data 段中，C++ 中不再区分了。\n",
    "    常量存储区（.data 段）：存放的是常量，不允许修改，程序运行结束自动释放。\n",
    "    代码区（.text 段）：存放代码，不允许修改，但可以执行。编译后的二进制文件存放在这里。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络/Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 三次握手四次挥手"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TCP提供了一种可靠、面向连接、字节流、传输层的服务，采用三次握手建立一个连接。采用4次挥手来关闭一个连接。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参见 https://zhuanlan.zhihu.com/p/53374516\n",
    "\n",
    "https://blog.csdn.net/qzcsu/article/details/72861891"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 计算机网络7层结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "物理层(PH)、数据链路层(DL)、网络层(N)、传输层(T)、会话层(S)、表示层(P)、应用层(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "详见 https://segmentfault.com/a/1190000039204681"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linux数据科学常用指令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LR LOSS func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM和神经网络相比，缺点是啥？\n",
    "\n",
    "    1. SVM在数据量《100K时，效果好，易解。对大数据不好求解。\n",
    "    2. SVM对参数不太敏感，kernal选择实际影响小，可调性差。\n",
    "    3. SVM需要自己做特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GBDT, XGBoost, LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 数据增广"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 过拟合和欠拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 类别不平衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### softmax公式、防止溢出方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC、AUC、F1 score （Metrics）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KL散度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### L1、L2正则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA & SVD 降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RNN和LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 梯度消失和爆炸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BN、LN、IN、GN 归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BN是给卷积层用的，dropout是全连接层用的，LN是transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dropout训练和推理区别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练中丢弃神经元，推理时没有丢弃。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropout随机丢弃，如何保证结果的复现？\n",
    "\n",
    "    固定dropout随机种子（randomSeed），固定随机初始化的randomSeed, cudnn精度损失（ban掉）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么推理不用dropout?\n",
    "\n",
    "    dropout本身是一种正则化，是对网络的一次随机取样。正则化的目的是在训练时，减少 模型复杂性，增强模型泛化能力。而预测时，使用的是训练好的权重，故而不需要dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取值一般在 e-2到e-4之间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### word2vec, glove, fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word2vec的负采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fasttext bucketsize有什么用？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the model will increase linearly with the number of buckets. The size of the input matrix is DIM x (VS + BS), where VS is the number of words in the vocabulary and BS is the number of buckets. The number of buckets does not have other influence on the model size.\n",
    "\n",
    "The buckets are used for __hashed features__ (such as character ngrams or word ngrams), which are used in addition to word features. In the input matrix, each word is represented by a vector, and the additional ngram features are represented by a fixed number of vectors (which corresponds to the number of buckets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### transformer\n",
    "\n",
    "transformer是一个典型的seq2seq模型。 应用： 文本翻译、ASR、TTS、语音翻译、chatBot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "self-attention\n",
    "    \n",
    "    实质：用q去找相关的K； 适用：输入是向量（vector set）\n",
    "\n",
    "    Q, K , V 公式背一下，手推一下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multi-head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么要多头？\n",
    "    \n",
    "    不同的q，能找到更多的相关性（相关本身是有多种形式/定义的）。多头适用于复杂任务如翻译和ASR， 可调参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional Encoding\n",
    "    \n",
    "    输入层加上位置向量。背好公式。 1. 原始是三角函数 2. 也许可以学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN vs Self-attention\n",
    "\n",
    "    CNN是简化版的self-attention， 人工设定的感受野。 self-attention自己学习出“感受野”。\n",
    "    所以合理设定self-attention的参数，也能达到CNN的效果，做图像任务\n",
    "\n",
    "    CNN good for less data; \n",
    "    self-attention good for more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN vs Self-attention\n",
    "    \n",
    "    1. RNN不能并行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder\n",
    "    \n",
    "    输入：向量； 输出：同样长度向量； 架构：input + self-attention + ADD&NORM(residual + layer norm) + FC + ADD&NORM(residual + layer norm) = output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder\n",
    "    \n",
    "    AT Decoder\n",
    "    \n",
    "    输入：BEGIN + Decoder output(previous layer) （ignore the input from encoder）\n",
    "    结构：multi-head self-attenion加入了mask。使得输出一个一个产生。\n",
    "    输出：END特殊字符\n",
    "    \n",
    "    NAT Decoder\n",
    "    输入： n个BEGIN; 输出n个END\n",
    "    好处：可以控制输出长度。 可以并行计算\n",
    "    劣势：NAT performance不如AT\n",
    "    问题：如何确定输出长度？ 1. 用一个分类器预测输出长度 2. 固定一个很长的长度，END后的输出直接忽略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder-Decoder\n",
    "    \n",
    "    encoder输出如何到decoder?\n",
    "    cross attention. q来自decoder, kv来自encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Transformer训练Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy Mechanism\n",
    "    \n",
    "    目的：把正确的答案当做decoder的输入。对于某些任务，没有必要让decoder自己创造输出。\n",
    "    应用：chat-bot，summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guided Attention\n",
    "    \n",
    "    目的：有时候，如tts, asr, 翻译，出现漏声、漏译。(missing some inputs)。需要制定一定方式的attention。\n",
    "    方式： Location-Aware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beam Search\n",
    "    \n",
    "    适用：答案比较唯一，如ASR\n",
    "    不适用：答案比较随机，如TTS。  Randomness is needed for decoder when generating sequence in some taks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing Evaluation Metrics?\n",
    "    \n",
    "    翻译问题， 训练的时候min cross entropy，评估的时候max BLEU score. 两者没有那么直接相关。因为训练的时候看的是单个词，BLEU是两个句子比较。\n",
    "    Loss为什么用CROSS ENTROPY而不用BLEU？ 因为Bleu不可微分。\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exposure Bias\n",
    "    \n",
    "    问题描述：输入给decoder的通常我们认为都是“完全正确”的，测试的时候，decoder看到的是自己的输出，会看到一些错误的输入。一步错，步步错。\n",
    "    解决思路：decoder输入加入noise。即Scheduled Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HMM & CRF & NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentiment Analysis, Aspect-Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Marian NMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### langDetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Bert蒸馏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### int8量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bolt框架思路与MindSpore量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 高性能计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CUDA的global、device、host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### kernel、stream、memory、event等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tensorrt推理和插件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fastTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPU内存类型和速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
